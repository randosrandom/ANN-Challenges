{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.3"},"colab":{"provenance":[],"collapsed_sections":[]}},"cells":[{"cell_type":"markdown","metadata":{"id":"1OtIP58drr0g"},"source":["# Introductive code"]},{"cell_type":"markdown","metadata":{"id":"BJG2y_ninv7-"},"source":["In order to work properly, our notebook requires 2 folders:\n","\n","+ \"MaskDataset\" folder, which is the result of unzipping 'artificial-neural-networks-and-deep-learning-2020.zip': we've created a cell that unzips the file, but it should be run only if \"MaskDataset\" folder wasn't already created\n","\n","+ \"MaskDatasetSorted\" folder, which contains three folders (one per label) with all the images for flow_from_directory: it can be created running the three code cells below the \"Sort the images for flow_from_directory method\" title, and each of them should be run only 1 time (in order to avoid multiple copies of the same image)"]},{"cell_type":"code","metadata":{"id":"jR_EDtobrCo2"},"source":["# Print all the intermediate operations (for debugging)\n","\n","from IPython.core.interactiveshell import InteractiveShell\n","InteractiveShell.ast_node_interactivity = \"all\""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Plj85XWYr3J5"},"source":["# Import most relevant libraries\n","\n","import os\n","import tensorflow as tf\n","import numpy as np\n","\n","\n","# Import library for handling json files\n","\n","import json\n","\n","\n","# Import shutil for the copy in sorted folders\n","\n","import shutil"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"TkBfCKBPr9KT"},"source":["# Fix a seed\n","\n","SEED = 1234\n","tf.random.set_seed(SEED)\n","np.random.seed(SEED)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Zmii4hOHrgRF","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1605733465934,"user_tz":-60,"elapsed":17526,"user":{"displayName":"Andrea Boselli","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjTT0DD5_ctcwk1BCWC99SFDQm1i1GG71SnE5ZXDw=s64","userId":"10139055795145528550"}},"outputId":"ac3d8c28-c47a-416f-db38-cea851f1ae4a"},"source":["# Add Colab (with Drive)\n","\n","from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"xqR8ihRjsuGF"},"source":["# If the \"MaskDataset\" folder wasn't already created, this cell unzips the zip file and creates \"MaskDataset\";\n","# please run this cell only if \"MaskDataset\" wasn't already created\n","\n","!unzip '/content/drive/My Drive/ANNDL_Results/Challenge1/artificial-neural-networks-and-deep-learning-2020.zip' -d '/content/drive/My Drive/ANNDL_Results/Challenge1'"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"FibacQUT5-Ro"},"source":["# Path to the current working directory (which contains MaskDataset folder)\n","\n","cwd = '/content/drive/My Drive/ANNDL_Results/Challenge1' # Working directory, with the dataset folder (we had issues with os.getcwd())\n","\n","# The following variables are inherited from previous code for Kaggle: they may be \n","# changed to switch to Kaggle without changing the rest of the implementation\n","\n","work_dir = cwd\n","work_dir2 = cwd\n","work_dir3 = cwd"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ml0kjpqIuRrA"},"source":["# Path to the dataset folder (MaskDataset folder must be already created)\n","\n","dataset_dir = os.path.join(work_dir,\"MaskDataset\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"cRXza3vKuVNn"},"source":["# Sort the images for flow_from_directory method"]},{"cell_type":"markdown","metadata":{"id":"QO5BPlMh5-Rx"},"source":["Run the following 3 cells to create \"MaskDatasetSorted\" folder, which contains three folders (one per label) with all the images for flow_from_directory. Please run these 3 cells only if \"MaskDatasetSorted\" wasn't already created"]},{"cell_type":"code","metadata":{"id":"K3KexZ8kudeZ"},"source":["# From the file .json, extract a dictionary with:\n","\n","# Key: name of the image\n","# Value: label of the image\n","\n","with open(os.path.join(dataset_dir,\"train_gt.json\")) as json_file: \n","    labels = json.load(json_file)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"i0VS3V58wfEX"},"source":["# Create the folders for flow_from_directory method\n","\n","sorted_training_dir = os.path.join(work_dir2,\"MaskDatasetSorted\")\n","if not os.path.exists(sorted_training_dir):\n","    os.makedirs(sorted_training_dir)\n","\n","folder_0 = os.path.join(sorted_training_dir,\"label0\")\n","if not os.path.exists(folder_0):\n","    os.makedirs(folder_0)\n","    \n","folder_1 = os.path.join(sorted_training_dir,\"label1\")\n","if not os.path.exists(folder_1):\n","    os.makedirs(folder_1)\n","\n","folder_2 = os.path.join(sorted_training_dir,\"label2\")\n","if not os.path.exists(folder_2):\n","    os.makedirs(folder_2)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"qaQN01t15-R1"},"source":["# Copy the images in the proper folder\n","\n","training_dir = os.path.join(dataset_dir, 'training')\n","\n","for name in labels.keys():\n","    photo_dir = os.path.join(training_dir,name)\n","    \n","    if labels[name] == 0:\n","        shutil.copy2(photo_dir,folder_0)\n","    if labels[name] == 1:\n","        shutil.copy2(photo_dir,folder_1)\n","    if labels[name] == 2:\n","        shutil.copy2(photo_dir,folder_2)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"agmpcp6Us4PT"},"source":["# Set all the necessary variables in ImageDataGenerator"]},{"cell_type":"code","metadata":{"id":"N7PemM47tT6F"},"source":["from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","\n","apply_data_augmentation = True\n","\n","# Create training ImageDataGenerator object (for data augmentation)\n","\n","if apply_data_augmentation:\n","    train_data_gen = ImageDataGenerator(rotation_range=10,\n","                                        width_shift_range=0,\n","                                        height_shift_range=0,\n","                                        zoom_range=0.15,\n","                                        horizontal_flip=True,\n","                                        vertical_flip=False,\n","                                        fill_mode='constant',\n","                                        cval=0,\n","                                        rescale=1./255,\n","                                        validation_split = 0.08)\n","else:\n","    train_data_gen = ImageDataGenerator(rescale=1./255,\n","                                        validation_split = 0.08)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"gr6h5KKJuc7-"},"source":["# Create train and validation generators"]},{"cell_type":"code","metadata":{"id":"ddfwk1B55-R4"},"source":["# Path to the training folder (data will be splitted, using ImageDataGenerator objects with flow_from_directory method)\n","\n","training_dir = os.path.join(work_dir2, 'MaskDatasetSorted')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"YBeYpOXDurKo"},"source":["# Some useful parameters\n","\n","# Batch size\n","bs = 32\n","\n","# img shape\n","img_h = 256\n","img_w = 256\n","\n","# Number of classes\n","num_classes = 3"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"eJI6LRR01TWj","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1605730367395,"user_tz":-60,"elapsed":26580,"user":{"displayName":"Andrea Boselli","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjTT0DD5_ctcwk1BCWC99SFDQm1i1GG71SnE5ZXDw=s64","userId":"10139055795145528550"}},"outputId":"f369250e-3456-4bc6-c17b-56a40cf5281e"},"source":["# Create generators to read images\n","\n","decide_class_indices = True\n","if decide_class_indices:\n","    classes = ['label0',    # 0\n","               'label1',    # 1\n","               'label2']    # 2\n","else:\n","    classes=None\n","\n","# Training\n","    \n","train_gen = train_data_gen.flow_from_directory(training_dir,\n","                                               target_size=(img_h, img_w),\n","                                               color_mode=\"rgb\",\n","                                               classes=classes,\n","                                               class_mode='categorical',\n","                                               batch_size=bs,\n","                                               shuffle=True,\n","                                               seed=SEED,\n","                                               subset='training')\n","\n","# Validation\n","\n","valid_gen = train_data_gen.flow_from_directory(training_dir,\n","                                               target_size=(img_h, img_w),\n","                                               color_mode=\"rgb\",\n","                                               classes=classes,\n","                                               class_mode='categorical',\n","                                               batch_size=bs,\n","                                               shuffle=True,\n","                                               seed=SEED,\n","                                               subset='validation')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Found 5166 images belonging to 3 classes.\n","Found 448 images belonging to 3 classes.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"oKwBDHQZ5-SB","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1605730373034,"user_tz":-60,"elapsed":506,"user":{"displayName":"Andrea Boselli","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjTT0DD5_ctcwk1BCWC99SFDQm1i1GG71SnE5ZXDw=s64","userId":"10139055795145528550"}},"outputId":"92bb9131-f448-4b08-873f-cb00587ee272"},"source":["# Check how keras assigned the labels\n","train_gen.class_indices"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'label0': 0, 'label1': 1, 'label2': 2}"]},"metadata":{"tags":[]},"execution_count":13}]},{"cell_type":"code","metadata":{"id":"itn22HFJitsp"},"source":["# Create Dataset objects both for training and for validation with tf.data.Dataset.from_generator\n","\n","\n","# Training\n","\n","train_dataset = tf.data.Dataset.from_generator(lambda: train_gen,\n","                                               output_types=(tf.float32, tf.float32),\n","                                               output_shapes=([None, img_h, img_w, 3], [None, num_classes]))\n","train_dataset = train_dataset.repeat()\n","\n","\n","# Validation\n","\n","valid_dataset = tf.data.Dataset.from_generator(lambda: valid_gen, \n","                                               output_types=(tf.float32, tf.float32),\n","                                               output_shapes=([None, img_h, img_w, 3], [None, num_classes]))\n","valid_dataset = valid_dataset.repeat()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"5GALFD_qjLky"},"source":["# Build and fit the model"]},{"cell_type":"code","metadata":{"id":"PWafQEJR5-SF"},"source":["# Set the model\n","\n","start_f = 32\n","depth = 5\n","\n","model = tf.keras.Sequential()\n","\n","# Perform features extraction with convolutional layers\n","\n","for i in range(depth):\n","\n","    if i == 0:\n","        input_shape = [img_h, img_w, 3]\n","    else:\n","        input_shape=[None]\n","\n","    # Conv block: Conv2D -> Activation -> Pooling\n","    model.add(tf.keras.layers.Conv2D(filters=start_f, \n","                                     kernel_size=(3, 3),\n","                                     strides=(1, 1),\n","                                     padding='same',\n","                                     input_shape=input_shape))\n","    model.add(tf.keras.layers.ReLU())\n","    model.add(tf.keras.layers.MaxPool2D(pool_size=(2, 2)))\n","\n","    start_f *= 2\n","    \n","# Set the fully connected layers for classification\n","\n","model.add(tf.keras.layers.Flatten())\n","model.add(tf.keras.layers.Dropout(0.25))\n","model.add(tf.keras.layers.Dense(units=256, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.001)))\n","model.add(tf.keras.layers.Dense(units=32, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.001)))\n","model.add(tf.keras.layers.Dense(units=num_classes, activation='softmax'))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Qm5nKNWSj6uv","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1605730405382,"user_tz":-60,"elapsed":518,"user":{"displayName":"Andrea Boselli","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjTT0DD5_ctcwk1BCWC99SFDQm1i1GG71SnE5ZXDw=s64","userId":"10139055795145528550"}},"outputId":"6fc391d7-f881-4bbb-c16b-27aaf76cd199"},"source":["# Visualize created model as a table\n","\n","model.summary()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Model: \"sequential\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","conv2d (Conv2D)              (None, 256, 256, 32)      896       \n","_________________________________________________________________\n","re_lu (ReLU)                 (None, 256, 256, 32)      0         \n","_________________________________________________________________\n","max_pooling2d (MaxPooling2D) (None, 128, 128, 32)      0         \n","_________________________________________________________________\n","conv2d_1 (Conv2D)            (None, 128, 128, 64)      18496     \n","_________________________________________________________________\n","re_lu_1 (ReLU)               (None, 128, 128, 64)      0         \n","_________________________________________________________________\n","max_pooling2d_1 (MaxPooling2 (None, 64, 64, 64)        0         \n","_________________________________________________________________\n","conv2d_2 (Conv2D)            (None, 64, 64, 128)       73856     \n","_________________________________________________________________\n","re_lu_2 (ReLU)               (None, 64, 64, 128)       0         \n","_________________________________________________________________\n","max_pooling2d_2 (MaxPooling2 (None, 32, 32, 128)       0         \n","_________________________________________________________________\n","conv2d_3 (Conv2D)            (None, 32, 32, 256)       295168    \n","_________________________________________________________________\n","re_lu_3 (ReLU)               (None, 32, 32, 256)       0         \n","_________________________________________________________________\n","max_pooling2d_3 (MaxPooling2 (None, 16, 16, 256)       0         \n","_________________________________________________________________\n","conv2d_4 (Conv2D)            (None, 16, 16, 512)       1180160   \n","_________________________________________________________________\n","re_lu_4 (ReLU)               (None, 16, 16, 512)       0         \n","_________________________________________________________________\n","max_pooling2d_4 (MaxPooling2 (None, 8, 8, 512)         0         \n","_________________________________________________________________\n","flatten (Flatten)            (None, 32768)             0         \n","_________________________________________________________________\n","dropout (Dropout)            (None, 32768)             0         \n","_________________________________________________________________\n","dense (Dense)                (None, 256)               8388864   \n","_________________________________________________________________\n","dense_1 (Dense)              (None, 32)                8224      \n","_________________________________________________________________\n","dense_2 (Dense)              (None, 3)                 99        \n","=================================================================\n","Total params: 9,965,763\n","Trainable params: 9,965,763\n","Non-trainable params: 0\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"GoWnZJ3ckHXE"},"source":["# Optimization params\n","\n","# Loss\n","loss = tf.keras.losses.CategoricalCrossentropy()\n","\n","\n","# Learning rate\n","lr = 1e-4\n","optimizer = tf.keras.optimizers.Adam(learning_rate=lr)\n","\n","\n","# Validation metrics\n","metrics = ['accuracy']\n","\n","\n","# Compile Model\n","model.compile(optimizer=optimizer, loss=loss, metrics=metrics)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Ri2_tTo93Sfy"},"source":["We trained the model for several times running the *model.fit* cell many times (in order to check the validity of the model). You can see below the result of the last 5 epochs (being novice, we overwrote the previous results). Our checkpoint is one of the results of this approach. The following cell is taken from the lab session, saves checkpoints and performs early stopping. If you don't want checkpoints, please comment the line '*callbacks.append(ckpt_callback)*'. To replicate our model, please run *model.fit* with around 65 epochs."]},{"cell_type":"code","metadata":{"id":"PLQAs_cTJMe1"},"source":["import os\n","from datetime import datetime\n","\n","cwd = cwd  # use your local directory if you are not using Drive\n","\n","exps_dir = os.path.join(cwd, 'classification_experiments_')\n","if not os.path.exists(exps_dir):\n","    os.makedirs(exps_dir)\n","\n","now = datetime.now().strftime('%b%d_%H-%M-%S')\n","\n","exp_name = 'Model_3'\n","\n","exp_dir = os.path.join(exps_dir, exp_name + '_' + str(now))\n","if not os.path.exists(exp_dir):\n","    os.makedirs(exp_dir)\n","    \n","callbacks = []\n","\n","# Model checkpoint\n","# ----------------\n","ckpt_dir = os.path.join(exp_dir, 'ckpts')\n","if not os.path.exists(ckpt_dir):\n","    os.makedirs(ckpt_dir)\n","\n","ckpt_callback = tf.keras.callbacks.ModelCheckpoint(filepath=os.path.join(ckpt_dir, 'cp_{epoch:02d}.ckpt'), save_best_only=True,\n","                                                   save_weights_only=True)  # False to save the model directly\n","callbacks.append(ckpt_callback)\n","\n","# Early Stopping\n","\n","early_stop = True\n","if early_stop:\n","    es_callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5)\n","    callbacks.append(es_callback)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"dgFBSpqnkhLU","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1605291821933,"user_tz":-60,"elapsed":494897,"user":{"displayName":"randeep singh","photoUrl":"","userId":"05852941244413530926"}},"outputId":"d32b985c-6d5e-4457-cfd7-36404a8a5638"},"source":["# Fit the model (few epochs because of problems with checkpoints)\n","\n","model.fit(x=train_dataset,\n","          epochs=5,  \n","          steps_per_epoch=len(train_gen),\n","          validation_data=valid_dataset,\n","          validation_steps=len(valid_gen), \n","          callbacks=callbacks)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Epoch 1/5\n","162/162 [==============================] - 98s 605ms/step - loss: 0.2555 - accuracy: 0.9139 - val_loss: 0.5205 - val_accuracy: 0.8080\n","Epoch 2/5\n","162/162 [==============================] - 98s 607ms/step - loss: 0.2528 - accuracy: 0.9139 - val_loss: 0.4834 - val_accuracy: 0.8036\n","Epoch 3/5\n","162/162 [==============================] - 98s 603ms/step - loss: 0.2559 - accuracy: 0.9117 - val_loss: 0.4482 - val_accuracy: 0.8147\n","Epoch 4/5\n","162/162 [==============================] - 99s 609ms/step - loss: 0.2483 - accuracy: 0.9185 - val_loss: 0.4429 - val_accuracy: 0.8415\n","Epoch 5/5\n","162/162 [==============================] - 98s 608ms/step - loss: 0.2392 - accuracy: 0.9202 - val_loss: 0.5417 - val_accuracy: 0.8013\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<tensorflow.python.keras.callbacks.History at 0x7f9a105ebcf8>"]},"metadata":{"tags":[]},"execution_count":38}]},{"cell_type":"code","metadata":{"id":"HnAu2-wc3azj","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1605730427836,"user_tz":-60,"elapsed":2654,"user":{"displayName":"Andrea Boselli","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjTT0DD5_ctcwk1BCWC99SFDQm1i1GG71SnE5ZXDw=s64","userId":"10139055795145528550"}},"outputId":"78d68ee2-68c9-4c1f-9a81-1da17770aba7"},"source":["model.load_weights(os.path.join('/content/drive/My Drive/ANNDL_Results/Challenge1/Our_best_model_weights', 'BestCheckpoint.ckpt'))"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7f6b328e1518>"]},"metadata":{"tags":[]},"execution_count":19}]},{"cell_type":"markdown","metadata":{"id":"qMT8gkjHLeEZ"},"source":["# Test the model, generate the csv file"]},{"cell_type":"code","metadata":{"id":"HaNzRvLKLkZu"},"source":["# Import necessary libraries\n","\n","import os\n","\n","from datetime import datetime\n","\n","from PIL import Image"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"yFje3EQTNXFb"},"source":["# Given function for saving the csv file, once the experiment is complete\n","\n","def create_csv(results, results_dir='./'):\n","\n","    csv_fname = 'results_'\n","    csv_fname += datetime.now().strftime('%b%d_%H-%M-%S') + '.csv'\n","\n","    with open(os.path.join(results_dir, csv_fname), 'w') as f:\n","\n","        f.write('Id,Category\\n')\n","\n","        for key, value in results.items():\n","            f.write(key + ',' + str(value) + '\\n')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"cG7u2F0wODMH"},"source":["# our version\n","\n","test_dir = os.path.join(dataset_dir, 'test')\n","image_filenames = next(os.walk(test_dir))[2]\n","\n","results = {}\n","\n","# Iterate on each image\n","for image_name in image_filenames:\n","\n","   # Open image\n","   img = Image.open(os.path.join(test_dir, image_name)).convert('RGB')\n","\n","   # Create a tensor from each image\n","\n","   img_array = np.array(img.resize((img_w,img_h)))\n","   img_array = np.expand_dims(img_array, 0) \n","\n","   # Normalize, predict and add to the dictionary\n","   softmax = model.predict(x = (img_array/255.))\n","   prediction = tf.argmax(softmax,1)\n","   results[image_name] = int(prediction)\n","\n","# Create csv file with the given function\n","create_csv(results,work_dir3)"],"execution_count":null,"outputs":[]}]}